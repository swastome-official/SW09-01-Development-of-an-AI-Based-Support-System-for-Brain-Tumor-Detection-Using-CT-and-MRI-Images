{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3s3lmuyycXeDJ8SCWAbuA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swastome-official/SW09-01-Development-of-an-AI-Based-Support-System-for-Brain-Tumor-Detection-Using-CT-and-MRI-Images/blob/main/SW09_01_Development_of_an_AI_Based_Support_System_for_Brain_Tumor_Detection_Using_CT_and_MRI_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMjpZglc0DTC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define paths to training and testing directories\n",
        "dataset_path = \"/path/to/brain-tumor-mri-dataset\"  # Update with actual path after downloading\n",
        "train_dir = os.path.join(dataset_path, \"Training\")\n",
        "test_dir = os.path.join(dataset_path, \"Testing\")\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    try:\n",
        "        # Read image in grayscale\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            return None\n",
        "        # Basic quality check: Remove images with extreme intensity (e.g., nearly all black/white)\n",
        "        if np.std(img) < 10 or np.mean(img) < 20 or np.mean(img) > 235:\n",
        "            return None\n",
        "        # Resize image\n",
        "        img = cv2.resize(img, target_size)\n",
        "        # Normalize pixel values to [0, 1]\n",
        "        img = img / 255.0\n",
        "        return img\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_dataset(directory, target_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = preprocess_image(img_path, target_size)\n",
        "            if img is not None:\n",
        "                images.append(img)\n",
        "                # Encode labels: 0=glioma, 1=meningioma, 2=notumor, 3=pituitary\n",
        "                labels.append(class_names.index(class_name))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    # Reshape images to include channel dimension\n",
        "    images = images.reshape(-1, target_size[0], target_size[1], 1)\n",
        "    return images, labels, class_names\n",
        "\n",
        "# Load training and testing data\n",
        "train_images, train_labels, class_names = load_dataset(train_dir)\n",
        "test_images, test_labels, _ = load_dataset(test_dir)\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Validation/test data generator (no augmentation)\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels_cat = tf.keras.utils.to_categorical(train_labels, num_classes=4)\n",
        "test_labels_cat = tf.keras.utils.to_categorical(test_labels, num_classes=4)\n",
        "\n",
        "# Create CNN model\n",
        "def create_cnn_model(input_shape=(224, 224, 1), num_classes=4):\n",
        "    model = Sequential([\n",
        "        # First convolutional block\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        # Second convolutional block\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        # Third convolutional block\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        # Flatten and dense layers\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Initialize and compile model\n",
        "model = create_cnn_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_datagen.flow(train_images, train_labels_cat, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=test_datagen.flow(test_images, test_labels_cat, batch_size=batch_size),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels_cat, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = test_labels\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('brain_tumor_cnn_model.h5')"
      ]
    }
  ]
}