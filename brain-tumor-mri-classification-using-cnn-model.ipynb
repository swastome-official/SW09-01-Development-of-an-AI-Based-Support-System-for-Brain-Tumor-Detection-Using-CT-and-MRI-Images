{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"eVVTuPp65mR9"}},{"cell_type":"code","source":"# Standard libraries\nimport os  # OS operations\nimport shutil  # File operations\n\n# Data handling\nimport pandas as pd  # DataFrames\nimport numpy as np  # Numerical ops\n\n# Visualization\nimport matplotlib.pyplot as plt  # Plots\nimport seaborn as sns  # Statistical plots\n\n# KaggleHub for downloading datasets/models\nimport kagglehub\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Computer vision\nimport cv2  # Image processing\n\n# Scikit-learn utilities and metrics\nfrom sklearn.utils import compute_class_weight\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n\n# TensorFlow & Keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\nfrom tensorflow.keras.layers import Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"id":"px5Qtfsz57cR","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T23:14:56.831711Z","iopub.execute_input":"2025-08-23T23:14:56.832047Z","iopub.status.idle":"2025-08-23T23:15:17.627356Z","shell.execute_reply.started":"2025-08-23T23:14:56.832019Z","shell.execute_reply":"2025-08-23T23:15:17.626371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{"id":"tfX22ZmuCl8c"}},{"cell_type":"code","source":"data = \"/kaggle/input/brain-tumor-mri-dataset\"","metadata":{"id":"1AlOWmgg5wDk","outputId":"61ce14cf-7fba-4d68-ba06-9dd8dfeeaad9","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T23:15:17.628821Z","iopub.execute_input":"2025-08-23T23:15:17.629489Z","iopub.status.idle":"2025-08-23T23:15:17.633964Z","shell.execute_reply.started":"2025-08-23T23:15:17.629462Z","shell.execute_reply":"2025-08-23T23:15:17.633033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to count images in each directory\ndef count_images_in_dirs(base_dir):\n    dir_counts = {}\n    for root, _, files in os.walk(base_dir):\n        # Filter out non-image files if necessary, here we assume all are images\n        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n        if image_files: # Only add directory if it contains images\n            dir_counts[root] = len(image_files)\n    return dir_counts\n\ncount_images_in_dirs(data)","metadata":{"id":"pe-5AmZWpRrO","outputId":"3b812d5e-ad16-4e39-af42-10785125a441","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T23:15:17.63741Z","iopub.execute_input":"2025-08-23T23:15:17.63773Z","iopub.status.idle":"2025-08-23T23:15:28.970161Z","shell.execute_reply.started":"2025-08-23T23:15:17.637701Z","shell.execute_reply":"2025-08-23T23:15:28.969402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data spliting to (Train - Validation - Test)","metadata":{"id":"enFZRIxyHC7G"}},{"cell_type":"code","source":"# Input and Output Paths\nbase_dir = '/content/'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\ntest_dir = os.path.join(base_dir, 'test')\n\n# Create output directories\nfor split_dir in [train_dir, validation_dir, test_dir]:\n    os.makedirs(split_dir, exist_ok=True)\n\n# Categories from your dataset\ncategories = ['pituitary', 'notumor', 'meningioma', 'glioma']\n\n# Split ratios\ntrain_ratio = 0.8\nvalidation_ratio = 0.2\ntest_ratio = 1 # This is not used in the current split logic, as train and val are taken from \"Training\" and test from \"Testing\"\n\n# Split and copy\nfor category in categories:\n    train_category_path = os.path.join(data, 'Training', category)\n    test_category_path = os.path.join(data, 'Testing', category)\n\n    # Process training and validation data\n    if os.path.exists(train_category_path):\n        image_files = os.listdir(train_category_path)\n        np.random.shuffle(image_files)\n\n        num_images = len(image_files)\n        num_train = int(train_ratio * num_images)\n        num_val = int(validation_ratio * num_images)\n\n        train_files = image_files[:num_train]\n        val_files = image_files[num_train:num_train + num_val]\n\n        # Copy helper\n        def copy_files(file_list, src_dir, dest_dir):\n            dest_category_dir = os.path.join(dest_dir, category)\n            os.makedirs(dest_category_dir, exist_ok=True)\n            for file in file_list:\n                src_path = os.path.join(src_dir, file)\n                dst_path = os.path.join(dest_category_dir, file)\n                shutil.copy(src_path, dst_path)\n\n        copy_files(train_files, train_category_path, train_dir)\n        copy_files(val_files, train_category_path, validation_dir)\n    else:\n        print(f\"Training directory not found for category: {category}\")\n\n    # Process test data\n    if os.path.exists(test_category_path):\n        test_files = os.listdir(test_category_path)\n        copy_files(test_files, test_category_path, test_dir)\n    else:\n        print(f\"Testing directory not found for category: {category}\")\n\nprint(\"Data split completed!\")","metadata":{"id":"ccQZ1p8wpPcS","outputId":"01993134-365c-44fd-af1c-4e5fc41e01db"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Count image in each directory","metadata":{"id":"teQqgzhgHJAP"}},{"cell_type":"code","source":"# Check image counts in train, validation, and test directories\nprint(\"Image counts in Train Directory:\")\ntrain_counts = count_images_in_dirs(train_dir)\nfor directory, count in train_counts.items():\n    print(f\"  {directory}: {count} images\")\n\nprint(\"\\nImage counts in Validation Directory:\")\nvalidation_counts = count_images_in_dirs(validation_dir)\nfor directory, count in validation_counts.items():\n    print(f\"  {directory}: {count} images\")\n\nprint(\"\\nImage counts in Test Directory:\")\ntest_counts = count_images_in_dirs(test_dir)\nfor directory, count in test_counts.items():\n    print(f\"  {directory}: {count} images\")\n\n# Optional: Print total counts per split\ntotal_train = sum(train_counts.values())\ntotal_validation = sum(validation_counts.values())\ntotal_test = sum(test_counts.values())\n\nprint(f\"\\nTotal images in train set: {total_train}\")\nprint(f\"Total images in validation set: {total_validation}\")\nprint(f\"Total images in test set: {total_test}\")","metadata":{"id":"mYAfyGnwWEeh","outputId":"82fc6aeb-efcf-491d-9875-588afa337d52"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display sample images","metadata":{"id":"AOLA1j1rHjMd"}},{"cell_type":"code","source":"# Function to display sample images\ndef display_sample_images(directory, num_images=4):\n    plt.figure(figsize=(12, 8))\n    i = 0\n    for category in categories:\n        category_path = os.path.join(directory, category)\n        image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f))][:num_images] # Take up to num_images\n\n        for img_file in image_files:\n            img_path = os.path.join(category_path, img_file)\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert BGR to RGB\n\n            plt.subplot(len(categories), num_images, i + 1)\n            plt.imshow(img)\n            plt.title(f\"{category}\")\n            plt.axis('off')\n            i += 1\n            if i >= len(categories) * num_images: # Stop if we have enough images\n              break\n        if i >= len(categories) * num_images: # Stop if we have enough images\n          break\n\n    plt.tight_layout()\n    plt.show()\n\n# Display sample images\ndisplay_sample_images(train_dir, num_images=4)","metadata":{"id":"nsfX7SVRZiC-","outputId":"c50e5e74-2c9b-4eb7-fdcd-49be405c1773"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Image Data Generator","metadata":{"id":"I8xVPsTIA-ya"}},{"cell_type":"code","source":"# Image Data Generator\ndatagen = ImageDataGenerator(rescale=1./255)\n\n# Create generators from the split directories\ntrain_generator = datagen.flow_from_directory(\n    train_dir,  # Use the training directory\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    validation_dir,  # Use the validation directory\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)\n\ntest_generator = datagen.flow_from_directory(\n    test_dir,  # Use the test directory\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False # Keep order for evaluation metrics\n)","metadata":{"id":"X0xctbeY6Sk9","outputId":"ec134656-dab3-48cf-f94c-3615c04e152c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN Model","metadata":{"id":"Iv7NoG4CEoqB"}},{"cell_type":"markdown","source":"## Build Model","metadata":{"id":"1vlyLgAwrANv"}},{"cell_type":"code","source":"# Clear previous models\ntf.keras.backend.clear_session()\n\n# Build the improved CNN\nmodel = Sequential([\n\n    # Block 1\n    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    MaxPooling2D(2, 2),\n\n    # Block 2\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n\n    # Block 3\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n\n    # Block 4\n    Conv2D(256, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n\n    # Flatten and Dense Layers\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dense(4, activation='softmax')  # 4 output classes\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Show model summary\nmodel.summary()","metadata":{"id":"YnEgNrr06bEP","outputId":"3e4c04c0-fc46-4ae2-de0c-35f46d0fc515"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Callbacks","metadata":{"id":"FYcCC8fOrC6T"}},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"id":"ZzmlCxg_63y4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training","metadata":{"id":"ufzSv8c0rF5e"}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=50,\n    validation_data=validation_generator,\n    callbacks=[early_stopping]\n)","metadata":{"id":"-LWxSiPs7EcF","outputId":"b5096562-1af6-4c68-fd8b-eaee0d5faf03"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{"id":"BQT6WDjHtVtq"}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Test Loss: {loss:.4f}\")","metadata":{"id":"sudv61nmtX9H","outputId":"af4c0dbc-9358-4b22-81f8-c061b549cd58"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Prediction and Testing","metadata":{"id":"CSfHTkfpEtmz"}},{"cell_type":"markdown","source":"## Training and Vaildataion","metadata":{"id":"U123WcSz1nkz"}},{"cell_type":"code","source":"fig = plt.figure(figsize=(14, 5))\n\n# Plot training & validation accuracy values\nfig.add_subplot(121)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nfig.add_subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\nplt.show()","metadata":{"id":"lmWGm9zh8DeX","outputId":"77a7ff66-c8ad-4efb-fb40-926757b5991e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Make Prediction","metadata":{"id":"DleL_7bSqjcE"}},{"cell_type":"code","source":"# Get true labels and predicted probabilities for the test set\ny_true = test_generator.classes\ny_pred_prob = model.predict(test_generator)\n\n# Get predicted labels\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Get class names\nclass_names = list(test_generator.class_indices.keys())","metadata":{"id":"2sqcB7Cs8lcq","outputId":"b95c1fd6-fcf5-4751-f541-4b4c1ab37cc3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Classification Report","metadata":{"id":"H8oIv5GzqmHs"}},{"cell_type":"code","source":"report = classification_report(y_true, y_pred, target_names=class_names)\nprint(\"Classification Report:\\n\", report)","metadata":{"id":"Uq6VPe3Wt_sn","outputId":"04108031-a587-4338-c1ab-ab275dd515a6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{"id":"fbWaUOHDqrqM"}},{"cell_type":"code","source":"# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"Kr-x9qDR8XXm","outputId":"82d03660-1362-480c-9421-ef5930410f0e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ROC Curve","metadata":{"id":"s4PdbtlIqwV7"}},{"cell_type":"code","source":"# Binarize the true labels for multi-class ROC\ny_true_binarized = label_binarize(y_true, classes=np.arange(test_generator.num_classes))\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(test_generator.num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot the ROC curves\nplt.figure(figsize=(10, 8))\nfor i in range(test_generator.num_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"Jv5S02Lk8N5p","outputId":"474ba73a-39fc-4c58-db8a-cbc19356a604"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Precision-Recall Curve","metadata":{"id":"Ydofm7fqqye0"}},{"cell_type":"code","source":"# Binarize the true labels for multi-class Precision-Recall\ny_true_binarized = label_binarize(y_true, classes=np.arange(test_generator.num_classes))\n\n# Compute Precision-Recall curve and average precision for each class\nprecision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(test_generator.num_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n    average_precision[i] = average_precision_score(y_true_binarized[:, i], y_pred_prob[:, i])\n\n# Plot the Precision-Recall curves\nplt.figure(figsize=(10, 8))\nfor i in range(test_generator.num_classes):\n    plt.plot(recall[i], precision[i], label='Precision-Recall curve of class {0} (area = {1:0.2f})'.format(i, average_precision[i]))\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall curve for multi-class')\nplt.legend(loc=\"lower left\")\nplt.show()","metadata":{"id":"zGL44heg8RMJ","outputId":"bb965965-cef6-4624-960d-8cc2b8b02a75"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing on one image from each class\n\n","metadata":{"id":"DlLD023RtoZa"}},{"cell_type":"code","source":"# Function to load and preprocess a single image\ndef load_and_preprocess_image(img_path, target_size=(128, 128)):\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    img = cv2.resize(img, target_size)  # Resize\n    img = img / 255.0  # Rescale\n    img = np.expand_dims(img, axis=0)  # Add batch dimension\n    return img\n\n# Get class names\nclass_names = list(test_generator.class_indices.keys())\n\n# Test on one image from each class\nplt.figure(figsize=(10, 10))\nfor i, category in enumerate(categories):\n    category_path = os.path.join(test_dir, category)\n    # Get the first image file in the category directory\n    image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f))]\n    if image_files:\n        img_file = image_files[0]\n        img_path = os.path.join(category_path, img_file)\n\n        # Load and preprocess the image\n        processed_img = load_and_preprocess_image(img_path)\n\n        # Make a prediction\n        predictions = model.predict(processed_img)\n        predicted_class_index = np.argmax(predictions)\n        predicted_class_name = class_names[predicted_class_index]\n\n        # Display the image and prediction\n        plt.subplot(2, 2, i + 1)\n        plt.imshow(load_and_preprocess_image(img_path, target_size=(128, 128))[0]) # Display the original image (not preprocessed for model)\n        plt.title(f\"Actual: {category}\\nPredicted: {predicted_class_name}\")\n        plt.axis('off')\n    else:\n        print(f\"No images found for category: {category} in the test set.\")\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"RRLA2KYitUBn","outputId":"0acf54d1-f001-42ff-8561-b5eb2a651304"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save Model","metadata":{"id":"-VxpJKnS1yFL"}},{"cell_type":"code","source":"model.save(f'brain_tumor_mri_classification_model_acc_{accuracy * 100:.2f}%.keras')","metadata":{"id":"YhnXPth91xzR"},"outputs":[],"execution_count":null}]}